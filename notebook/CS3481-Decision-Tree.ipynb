{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c62f8f5",
   "metadata": {},
   "source": [
    "# CS3481 Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953aa291",
   "metadata": {},
   "source": [
    "Tasks:  \n",
    "   (1) use sklearn to build a classification tree , try different parameters to the decision tree constructors  \n",
    "   (2) use graphviz to visualize the model of your decision tree. And compare their performances  (accuracy and confusion matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a5c355",
   "metadata": {},
   "source": [
    "Use the following command to import the required module form sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e6c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5e704f",
   "metadata": {},
   "source": [
    "## Preparing Dataset\n",
    "The dataset I use is the [UCI Forest Dataset](https://archive.ics.uci.edu/ml/datasets/Forest+type+mapping). I have downloaded its training dataset and testing dataset as \"training.csv\" and \"testing.csv\". These two csv files must be in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5212c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from csv training data as dataframe\n",
    "fr_dataset = dftrain = pd.read_csv(\"training.csv\", sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32214f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d ', 'o ', 'h ', 's ']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# access the entries using dataframe.iloc\n",
    "def select_distinct(col_idx: int) -> List[str]:\n",
    "    set_of_class_labels = set()\n",
    "    if (col_idx >= 0 and col_idx < len(fr_dataset.iloc[0, :])):\n",
    "        for class_label in fr_dataset.iloc[:, col_idx]:\n",
    "            if class_label not in set_of_class_labels:\n",
    "                set_of_class_labels.add(class_label)\n",
    "    else:\n",
    "        print(\"Your column index out of bound\")\n",
    "    return list(set_of_class_labels)\n",
    "select_distinct(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54d3ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing - Convert alphabetic labels into numerics\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "training_labels = fr_dataset.iloc[:, 0]\n",
    "labels = le.fit_transform(training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a560e00a",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Try out different parameters for the Decision Tree constructor.  \n",
    "\n",
    "To remove randomness, set ```random_state``` to a non-none value in the class constructor below, otherwise you will get different execution results in each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a291df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Tree A\n",
    "#clf = tree.DecisionTreeClassifier(max_depth=3)\n",
    "# Classification Tree B\n",
    "clf = tree.DecisionTreeClassifier(max_depth=3,criterion='entropy', max_features=None, random_state=2323) # fix random seed\n",
    "# Classification Tree C\n",
    "# clf = tree.DecisionTreeClassifier(max_depth=3, criterion='gini', max_features='sqrt')\n",
    "# Classification Tree D\n",
    "# clf = tree.DecisionTreeClassifier(max_depth=4)\n",
    "# Classification Tree E\n",
    "# clf = tree.DecisionTreeClassifier(max_depth=2)\n",
    "# Classification Tree F\n",
    "# clf = tree.DecisionTreeClassifier(max_depth=3, criterion='entropy', min_impurity_decrease=0.85)\n",
    "clf = clf.fit(fr_dataset.iloc[:,1:], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5684c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lclass_names: ['d ' 'h ' 'o ' 's ']\n"
     ]
    }
   ],
   "source": [
    "# visualize the tree\n",
    "lfeature_names = fr_dataset.columns[1:]\n",
    "# the real class_name labels is in the internal \"classes_\" attributes\n",
    "lclass_names = le.classes_\n",
    "print(f\"lclass_names: {lclass_names}\")\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,feature_names=lfeature_names,class_names=lclass_names,filled=True, rounded=True,special_characters=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd2fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "filepath = graph.render('Forest_Dataset2', format='png')\n",
    "print(filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127758bd",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98db5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the decision tree to test dataset\n",
    "fr_testset = pd.read_csv(\"testing.csv\", sep = ',')\n",
    "fr_testdata = fr_testset.iloc[:,1:]\n",
    "fr_prediction = clf.predict(fr_testdata)\n",
    "# the outcome from predict() is encoded int. Convert them to real class labels\n",
    "prediction_results = np.array([lclass_names[encoded_class] for encoded_class in fr_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19759027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for this Tree: \n",
      " 0.7846153846153846\n"
     ]
    }
   ],
   "source": [
    "# Evalutate prediction score\n",
    "clf1_score = accuracy_score(fr_testset.iloc[:,0], prediction_results)\n",
    "print(\"Accuracy score for this Tree: \\n\", clf1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26605201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73   0  12  20]\n",
      " [  0  29   0   9]\n",
      " [ 10   1  34   1]\n",
      " [  5  12   0 119]]\n"
     ]
    }
   ],
   "source": [
    "# See the Confusion Matrix for this tree\n",
    "print(confusion_matrix(fr_testset.iloc[:,0], prediction_results, labels=['d ','h ','o ','s ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c363a1",
   "metadata": {},
   "source": [
    "## Utility functions and test runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca2ae3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param haystack {pd.DataFrame} - the test dataset\n",
    "@param needle_criteria {function} - contains criteria such that this needle can be misclassified\n",
    "@return {pd.arraylike} one row from that dataset  \n",
    "'''\n",
    "def find_outliner(haystack, needle_criteria ):\n",
    "    row_iter = haystack.iterrows()\n",
    "    row_idx, row_data = next(row_iter)\n",
    "    while not row_data.empty:\n",
    "        try:\n",
    "            if (needle_criteria(row_data) == True):\n",
    "                return row_data\n",
    "            row_idx, row_data = next(row_iter)\n",
    "        except StopIteration as e:\n",
    "            print(\"Exit at row\", row_idx+1)\n",
    "            break\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9da1d488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit at row 325\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# misclassification Type (1)\n",
    "# def instance_d_mis_o_criteria(datarow) -> bool:\n",
    "#     is_all_cond_met = False\n",
    "#     if datarow.loc['class'] == 'd ':\n",
    "#         if datarow.loc['b2'] > 35.5:\n",
    "#             if datarow.loc['pred_minus_obs_H_b8'] <= 0.475:\n",
    "#                 if datarow.loc['pred_minus_obs_S_b3'] <= -1.83:\n",
    "#                     is_all_cond_met = True\n",
    "#     return is_all_cond_met\n",
    "# instance_d_mis_o =  find_outliner(fr_testset, instance_d_mis_o_criteria)# instance of 'd' misclassified as 'o'\n",
    "# def instance_d_mis_s_criteria(datarow)->bool:\n",
    "#     is_all_cond_met = False\n",
    "#     if datarow.loc['class'] == 'd ':\n",
    "#         if datarow.loc['b2'] <= 35.5:\n",
    "#             if datarow.loc['pred_minus_obs_H_b1'] <= 41.39:\n",
    "#                 if datarow.loc['pred_minus_obs_S_b1'] > -0.76:\n",
    "#                     is_all_cond_met = True\n",
    "#             else:\n",
    "#                 if datarow.loc['pred_minus_obs_H_b7'] > -17.815:\n",
    "#                     is_all_cond_met = True\n",
    "#     return is_all_cond_met\n",
    "# instance_d_mis_s = find_outliner(fr_testset, instance_d_mis_s_criteria)\n",
    "def instance_h_mis_s_criteria(datarow):\n",
    "    is_all_cond_met = False\n",
    "    if datarow.loc['class'] == 'h ':\n",
    "        if datarow.loc['b2'] <= 35.5:\n",
    "            if datarow.loc['pred_minus_obs_H_b1'] <= 41.39:\n",
    "                if datarow.loc['pred_minus_obs_S_b1'] > -0.76:\n",
    "                    is_all_cond_met = True\n",
    "            else:\n",
    "                if datarow.loc['pred_minus_obs_H_b7'] > -17.815:\n",
    "                    is_all_cond_met = True\n",
    "    return is_all_cond_met\n",
    "\n",
    "instance_h_mis_s = find_outliner(fr_testset, instance_h_mis_s_criteria)\n",
    "print(instance_h_mis_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f48d5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9',\n",
       "       'pred_minus_obs_H_b1', 'pred_minus_obs_H_b2',\n",
       "       'pred_minus_obs_H_b3', 'pred_minus_obs_H_b4',\n",
       "       'pred_minus_obs_H_b5', 'pred_minus_obs_H_b6',\n",
       "       'pred_minus_obs_H_b7', 'pred_minus_obs_H_b8',\n",
       "       'pred_minus_obs_H_b9', 'pred_minus_obs_S_b1',\n",
       "       'pred_minus_obs_S_b2', 'pred_minus_obs_S_b3',\n",
       "       'pred_minus_obs_S_b4', 'pred_minus_obs_S_b5',\n",
       "       'pred_minus_obs_S_b6', 'pred_minus_obs_S_b7',\n",
       "       'pred_minus_obs_S_b8', 'pred_minus_obs_S_b9'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b578fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
