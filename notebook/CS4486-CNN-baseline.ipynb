{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE9JGRbaO_Ex"
      },
      "source": [
        "## Baseline CNN model\n",
        "### [Kaggle - Cats vs Dogs](https://www.kaggle.com/c/dogs-vs-cats/data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbL8fLlHT8mX"
      },
      "source": [
        "This notebook references code by Kaggle user [angqx95](https://www.kaggle.com/code/angqx95/feature-extractor-fine-tuning-with-keras) on https://www.kaggle.com/code/angqx95/feature-extractor-fine-tuning-with-keras. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYw0NoYu8995"
      },
      "source": [
        "## Unzipping datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z_569N4f858R"
      },
      "outputs": [],
      "source": [
        "#Define some constants\n",
        "sample_path = \"./drive/MyDrive/Colab Notebooks/\"\n",
        "train_ds = \"train.zip\"\n",
        "\n",
        "batch_size = 32\n",
        "img_size = 256\n",
        "epochs = 5\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2VyRup0ROxHV"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "# extract ZIP into the folder\n",
        "with zipfile.ZipFile(os.path.join(sample_path, train_ds),\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"/tmp/dog_v_cats/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWQOMjm49C0p",
        "outputId": "593af0bc-0800-472e-86b2-760c97f9248e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are  25000 training data samples\n"
          ]
        }
      ],
      "source": [
        "# below is to correct the dataset path \n",
        "train_ds_dir = \"/tmp/dog_v_cats/train/\"\n",
        "\n",
        "print(\"There are \", len(os.listdir('/tmp/dog_v_cats/train')), \"training data samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9fi4mRjTx-i"
      },
      "source": [
        "## Data Formatting\n",
        "Labels: 1 for dog, 0 for cat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyY_wgfQTlO_",
        "outputId": "292c4696-2946-4eae-f78b-63ff701a1219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25000 images scanned at /tmp/dog_v_cats/train/\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def generate_paths_n_labels(directory):\n",
        "  ground_truth_labels = []  # '0' or '1' for cat and dog, respectively\n",
        "  img_paths = []  # the relative path of this image file \n",
        "  for file in os.listdir(directory):\n",
        "    img_paths.append(file)\n",
        "    if (file.split('.')[0] == 'cat'):\n",
        "      ground_truth_labels.append('0')\n",
        "    else:\n",
        "      ground_truth_labels.append('1')\n",
        "  print(len(ground_truth_labels), \"images scanned at\", directory)\n",
        "  return img_paths, ground_truth_labels\n",
        "\n",
        "\n",
        "train_img_paths, train_y = generate_paths_n_labels(train_ds_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "pTsYtUxnW787",
        "outputId": "6e9c355b-11c6-4392-8b7b-8b10cb753e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        filename class_label\n",
            "0   cat.7725.jpg           0\n",
            "1   cat.1508.jpg           0\n",
            "2  cat.12040.jpg           0\n",
            "3   cat.4954.jpg           0\n",
            "4  dog.11784.jpg           1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Cats vs. Dogs Images Distribution')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame({'filename': train_img_paths,\n",
        "                  'class_label': train_y})\n",
        "print(df.head())\n",
        "\n",
        "# showing the data distribution in the training set\n",
        "sns.countplot(x='class_label',data=df).set_title(\"Cats vs. Dogs Images Distribution\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58xnD3CtXATs"
      },
      "outputs": [],
      "source": [
        "#### FYI #####\n",
        "# Showing one image \n",
        "img = load_img(os.path.join( train_ds_dir, df['filename'].iloc[0]))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(img)\n",
        "##############"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LAaN10gb_bW"
      },
      "source": [
        "## Train-Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BaaHbcIJxTxI"
      },
      "outputs": [],
      "source": [
        "def generate_img_batch(dataframe, ds_dir): \n",
        "  '''dataframe : contains 2 cols, <path to image file>, <label for the image>\n",
        "     ds_dir = directory path on which  <path to image file> is based\n",
        "  '''\n",
        "  data_genarator = ImageDataGenerator(    # data augmentation\n",
        "                rescale=1./255,  # rescale to [0, 1]\n",
        "                shear_range=0.1,\n",
        "                zoom_range=0.1,\n",
        "                horizontal_flip=True\n",
        "                # preprocessing_function = \n",
        "                )\n",
        "  train_data_gen = data_genarator.flow_from_dataframe(\n",
        "                dataframe,\n",
        "                directory=ds_dir,\n",
        "                x_col='filename',\n",
        "                y_col='class_label',\n",
        "                target_size=(img_size, img_size),\n",
        "                batch_size = batch_size,\n",
        "                class_mode='binary',\n",
        "                interpolation='nearest'\n",
        "                )\n",
        "\n",
        "  return train_data_gen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNBUnQHsXIub",
        "outputId": "907496ae-68d9-4693-d9d1-cfe5d4d0a9a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 18750 validated image filenames belonging to 2 classes.\n",
            "Found 6250 validated image filenames belonging to 2 classes.\n",
            "size of training dataset: 18750\n",
            "size of validation dataset: 6250\n"
          ]
        }
      ],
      "source": [
        "# make data for validation set (accounts for 25% of all data)\n",
        "train_df, valid_df = train_test_split(df, test_size=0.25) \n",
        "\n",
        "train_gen = generate_img_batch(train_df, train_ds_dir) # training dataset generator\n",
        "valid_gen = generate_img_batch(valid_df, train_ds_dir) #  validation dataset generator\n",
        "\n",
        "print(\"size of training dataset: %d\" % (train_df.shape[0]))\n",
        "print(\"size of validation dataset: %d\" % (valid_df.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZkgfyoU_Gbe"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JhW0rQxpfbjM"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oriOmDBqoKPH",
        "outputId": "799aff09-c68d-4575-e44e-3e807db0994d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_35 (Conv2D)          (None, 254, 254, 16)      448       \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 252, 252, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 84, 84, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 82, 82, 32)        4640      \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 80, 80, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 40, 40, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 38, 38, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 36, 36, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 18, 18, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 8, 8, 32)          18464     \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 4, 4, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 353,713\n",
            "Trainable params: 353,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#model instantiation\n",
        "model=Sequential()\n",
        "model.add(Conv2D(16, (3,3), activation=\"relu\", input_shape=(img_size, img_size, 3)))\n",
        "model.add(Conv2D(16, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (3,3)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
        "model.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
        "model.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3), strides=(2,2), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", \n",
        "         # optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "         optimizer=RMSprop(learning_rate=1e-4),\n",
        "         metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hADZwPcgqhBe",
        "outputId": "d856163b-a1c0-43ee-8bb9-b0dc55bc7699"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1172/1172 [==============================] - 373s 317ms/step - loss: 0.6586 - accuracy: 0.5988 - val_loss: 0.6246 - val_accuracy: 0.6480\n",
            "Epoch 2/5\n",
            "1172/1172 [==============================] - 371s 316ms/step - loss: 0.5941 - accuracy: 0.6793 - val_loss: 0.5589 - val_accuracy: 0.7141\n",
            "Epoch 3/5\n",
            "1172/1172 [==============================] - 368s 314ms/step - loss: 0.5370 - accuracy: 0.7301 - val_loss: 0.5710 - val_accuracy: 0.7016\n",
            "Epoch 4/5\n",
            "1172/1172 [==============================] - 366s 313ms/step - loss: 0.5035 - accuracy: 0.7535 - val_loss: 0.5528 - val_accuracy: 0.7218\n",
            "Epoch 5/5\n",
            "1172/1172 [==============================] - 367s 313ms/step - loss: 0.4774 - accuracy: 0.7731 - val_loss: 0.4638 - val_accuracy: 0.7806\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ec60af190>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit_generator(train_gen,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=valid_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXIHmdOz2Baq",
        "outputId": "bd9ce227-455b-4191-8cc4-baf915f82c78"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation: accuracy = 0.785417  ;  loss = 0.464272 \n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate_generator(valid_gen, valid_gen.samples//batch_size, workers=12)\n",
        "print(\"Validation: accuracy = %f  ;  loss = %f \" % (accuracy, loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "UBIGHcle-U0_"
      },
      "outputs": [],
      "source": [
        "model.save(filepath=\"/content/drive/MyDrive/Colab Notebooks/CustomCNN_baseline.h5\",\n",
        "              include_optimizer=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7fktkhcVqD3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CS4486_Assignment3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
